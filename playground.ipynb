{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         label  \\\n",
      "0                      Battles   \n",
      "1                      Battles   \n",
      "2                      Battles   \n",
      "3                      Battles   \n",
      "4                      Battles   \n",
      "5                      Battles   \n",
      "6                      Battles   \n",
      "7                      Battles   \n",
      "8                      Battles   \n",
      "9                      Battles   \n",
      "10  Explosions/Remote violence   \n",
      "11  Explosions/Remote violence   \n",
      "12  Explosions/Remote violence   \n",
      "13  Explosions/Remote violence   \n",
      "14  Explosions/Remote violence   \n",
      "15  Explosions/Remote violence   \n",
      "16  Explosions/Remote violence   \n",
      "17  Explosions/Remote violence   \n",
      "18  Explosions/Remote violence   \n",
      "19  Explosions/Remote violence   \n",
      "20                    Protests   \n",
      "21                    Protests   \n",
      "22                    Protests   \n",
      "23                    Protests   \n",
      "24                    Protests   \n",
      "25                    Protests   \n",
      "26                    Protests   \n",
      "27                    Protests   \n",
      "28                    Protests   \n",
      "29                    Protests   \n",
      "30                       Riots   \n",
      "31                       Riots   \n",
      "32                       Riots   \n",
      "33                       Riots   \n",
      "34                       Riots   \n",
      "35                       Riots   \n",
      "36                       Riots   \n",
      "37                       Riots   \n",
      "38                       Riots   \n",
      "39                       Riots   \n",
      "40      Strategic developments   \n",
      "41      Strategic developments   \n",
      "42      Strategic developments   \n",
      "43      Strategic developments   \n",
      "44      Strategic developments   \n",
      "45      Strategic developments   \n",
      "46      Strategic developments   \n",
      "47      Strategic developments   \n",
      "48      Strategic developments   \n",
      "49      Strategic developments   \n",
      "50  Violence against civilians   \n",
      "51  Violence against civilians   \n",
      "52  Violence against civilians   \n",
      "53  Violence against civilians   \n",
      "54  Violence against civilians   \n",
      "55  Violence against civilians   \n",
      "56  Violence against civilians   \n",
      "57  Violence against civilians   \n",
      "58  Violence against civilians   \n",
      "59  Violence against civilians   \n",
      "\n",
      "                                                 text  \n",
      "0   On 1 December 2023, Russian and Ukrainian mili...  \n",
      "1   On 1 December 2023, Ukrainian military forces ...  \n",
      "2   On 30 November 2023, in Campo Grande (Mato Gro...  \n",
      "3   Around 1 December 2023 (as reported), SAF and ...  \n",
      "4   On 30 November 2023, Israeli forces opened fir...  \n",
      "5   On 30 November 2023, clashes took place betwee...  \n",
      "6   On 1 December 2023, in Chapadao do Sul (Mato G...  \n",
      "7   On 30 November 2023, JNIM militants attacked a...  \n",
      "8   On 1 December 2023, a clash between cousins re...  \n",
      "9   On 1 December 2023, an unidentified armed grou...  \n",
      "10  On 1 December 2023, Hamas militants fired rock...  \n",
      "11  On 1 December 2023, Hamas militants fired rock...  \n",
      "12  On 30 November 2023, SAF shelled artillery tar...  \n",
      "13  On 1 December 2023, Israeli fighter jets struc...  \n",
      "14  On 1 December 2023, Hezbollah forces fired sev...  \n",
      "15  On 30 November 2023, Israeli gunboats struck t...  \n",
      "16  On 1 December 2023, Russian military forces sh...  \n",
      "17  On 1 December 2023, Israeli artillery struck t...  \n",
      "18  On 1 December 2023, Russian military forces sh...  \n",
      "19  On 1 December 2023, QSD shelled the area of a ...  \n",
      "20  On 1 December 2023, victims of a housing fraud...  \n",
      "21  On 30 November 2023, in San Juan (Capital, San...  \n",
      "22  On 1 December 2023, demonstrators held a large...  \n",
      "23  On 1 December 2023, for the eight consecutive ...  \n",
      "24  On 1 December 2023, KCTU-affiliated Korean Met...  \n",
      "25  On 30 November 2023, members of the Oyetubo Jo...  \n",
      "26  On 1 December 2023, hundreds of Accredited Soc...  \n",
      "27  On 1 December 2023, journalists staged a demon...  \n",
      "28  On 30 November 2023, foreign protesters gather...  \n",
      "29  On 1 December 2023, in Chilca (Junin), around ...  \n",
      "30  On 1 December 2023, in Flores (Pernambuco), a ...  \n",
      "31  On 1 December 2023, Palestinian rioters clashe...  \n",
      "32  On 1 December 2023, in Fernando De La Mora (Ce...  \n",
      "33  On 30 November 2023, unidentified men exploded...  \n",
      "34  On 1 December 2023, Palestinian rioters clashe...  \n",
      "35  On 1 December 2023, Palestinian rioters clashe...  \n",
      "36  On 1 December 2023, rioterm likely vigilantes,...  \n",
      "37  On 30 November 2023, Palestinian rioters clash...  \n",
      "38  On 30 November 2023, Israeli settler rioters h...  \n",
      "39  On 1 December 2023, Palestinian rioters clashe...  \n",
      "40  Security measures: On 1 December 2023, Israeli...  \n",
      "41  Around 30 November 2023 (as reported), Turkish...  \n",
      "42  Property destruction: On 30 November 2023, Isr...  \n",
      "43  On 30 November 2023, police forces detained th...  \n",
      "44  Interception: On 1 December 2023, Israeli mili...  \n",
      "45  Looting: On 1 December 2023, Israeli forces se...  \n",
      "46  Non-violent activity: On 1 December 2023, US f...  \n",
      "47  Interception: On 1 December 2023, Hamas milita...  \n",
      "48  Looting: On 1 December 2023, Israeli settlers ...  \n",
      "49  Interception: On 30 November 2023, the iron do...  \n",
      "50  On 30 November 2023, regime forces opened fire...  \n",
      "51  On 30 November 2023, in Caracas - Libertador (...  \n",
      "52  On 30 November 2023, in Tijuana, Baja Californ...  \n",
      "53  Around 1 December 2023 (as reported), in Plan ...  \n",
      "54  On 30 November 2023, the Sokoto militia raided...  \n",
      "55  On 1 December 2023, in Thingangyun township (Y...  \n",
      "56  On 1 December 2023, in Manaus - West Zone (Ama...  \n",
      "57  On 30 November 2023, in Comalcalco, Tabasco, t...  \n",
      "58  Around 1 December 2023 (as reported), in Lagoa...  \n",
      "59  On 1 December 2023, 6-7 people including two S...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gamal\\AppData\\Local\\Temp\\ipykernel_26828\\2726814160.py:12: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sampled_df = df.groupby('event_type').apply(lambda x: x.sample(min(len(x), 10))).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "import cohere\n",
    "import pandas as pd\n",
    "# Instantiate the Cohere client\n",
    "api_key=\"0DlpJISOe7M8igl3vZPGJNPeTYs7hgNIbS7uhl5A\"\n",
    "co = cohere.Client(api_key)\n",
    "\n",
    "# Load your CSV file\n",
    "file_path = \"ACLED 2023 Subset.csv\"  # Replace with the actual path to your CSV file\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Select five random examples of each event type\n",
    "sampled_df = df.groupby('event_type').apply(lambda x: x.sample(min(len(x), 10))).reset_index(drop=True)\n",
    "\n",
    "# Keep only the 'event_type' and 'notes' columns\n",
    "sampled_df = sampled_df[['event_type', 'notes']]\n",
    "\n",
    "# Rename columns: 'event_type' to 'label' and 'notes' to 'text'\n",
    "sampled_df.rename(columns={'event_type': 'label', 'notes': 'text'}, inplace=True)\n",
    "\n",
    "# Save the result in CSV format for Cohere\n",
    "sampled_df.to_csv(\"cohere_prepared_single_label.csv\", index=False)\n",
    "\n",
    "# Optionally, save in JSONL format\n",
    "sampled_df.to_json(\"cohere_prepared_single_label.jsonl\", orient=\"records\", lines=True)\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(sampled_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "status_code: 400, body: {'message': 'invalid dataset type'}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m co \u001b[38;5;241m=\u001b[39m cohere\u001b[38;5;241m.\u001b[39mClient(api_key)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Step 1: Create Dataset for Single-Label Fine-Tuning\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m single_label_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mco\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msingle-label-dataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcohere_prepared_single_label.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Provide the correct path to your dataset\u001b[39;49;00m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msingle-label-finetune-input\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Wait for the dataset to be validated\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(single_label_dataset\u001b[38;5;241m.\u001b[39mawait_validation())\n",
      "File \u001b[1;32mc:\\Python\\Python311\\Lib\\site-packages\\cohere\\datasets\\client.py:259\u001b[0m, in \u001b[0;36mDatasetsClient.create\u001b[1;34m(self, name, type, data, keep_original_file, skip_malformed_input, keep_fields, optional_fields, text_separator, csv_delimiter, dry_run, eval_data, request_options)\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m typing\u001b[38;5;241m.\u001b[39mcast(DatasetsCreateResponse, construct_type(type_\u001b[38;5;241m=\u001b[39mDatasetsCreateResponse, object_\u001b[38;5;241m=\u001b[39m_response\u001b[38;5;241m.\u001b[39mjson()))  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m400\u001b[39m:\n\u001b[1;32m--> 259\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BadRequestError(\n\u001b[0;32m    260\u001b[0m         typing\u001b[38;5;241m.\u001b[39mcast(typing\u001b[38;5;241m.\u001b[39mAny, construct_type(type_\u001b[38;5;241m=\u001b[39mtyping\u001b[38;5;241m.\u001b[39mAny, object_\u001b[38;5;241m=\u001b[39m_response\u001b[38;5;241m.\u001b[39mjson()))  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     )\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m401\u001b[39m:\n\u001b[0;32m    263\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UnauthorizedError(\n\u001b[0;32m    264\u001b[0m         typing\u001b[38;5;241m.\u001b[39mcast(typing\u001b[38;5;241m.\u001b[39mAny, construct_type(type_\u001b[38;5;241m=\u001b[39mtyping\u001b[38;5;241m.\u001b[39mAny, object_\u001b[38;5;241m=\u001b[39m_response\u001b[38;5;241m.\u001b[39mjson()))  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    265\u001b[0m     )\n",
      "\u001b[1;31mBadRequestError\u001b[0m: status_code: 400, body: {'message': 'invalid dataset type'}"
     ]
    }
   ],
   "source": [
    "import cohere\n",
    "from cohere.finetuning import BaseModel, FinetunedModel, Settings\n",
    "from cohere.datasets import ParseInfo\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "# Instantiate the Cohere client\n",
    "api_key=os.getenv(\"COHERE_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"API key not found! Please set the COHERE_API_KEY in your .env file.\")\n",
    "co = cohere.Client(api_key)\n",
    "\n",
    "# Step 1: Create Dataset for Single-Label Fine-Tuning\n",
    "single_label_dataset = co.datasets.create(\n",
    "    name=\"single-label-dataset\",\n",
    "    data=open(\"cohere_prepared_single_label.csv\", \"rb\"),  # Provide the correct path to your dataset\n",
    "    type=\"single-label-finetune-input\",\n",
    "    parse_info=ParseInfo(delimiter=\",\")\n",
    ")\n",
    "\n",
    "# Wait for the dataset to be validated\n",
    "print(single_label_dataset.await_validation())\n",
    "\n",
    "# Step 2: Start the Fine-Tuning Job\n",
    "finetune = co.finetuning.create_finetuned_model(\n",
    "    request=FinetunedModel(\n",
    "        name=\"single-label-ft\",\n",
    "        settings=Settings(\n",
    "            base_model=BaseModel(base_type=\"BASE_TYPE_CLASSIFICATION\"),\n",
    "            dataset_id=single_label_dataset.id,\n",
    "        ),\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Wait for fine-tuning to complete and print the status\n",
    "print(f\"Fine-tune ID: {finetune.id}, Fine-tune Status: {finetune.status}\")\n",
    "\n",
    "# Step 3: Use the Fine-Tuned Model for Classification\n",
    "ft = co.finetuning.get_finetuned_model(finetune.id)\n",
    "\n",
    "response = co.classify(\n",
    "    inputs=[\"Classify this example text!\"],\n",
    "    model=ft.id + \"-ft\",  # Append \"-ft\" to the model ID as per Cohere's requirement\n",
    ")\n",
    "\n",
    "# Print the model's classification response\n",
    "print(response.classifications)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
